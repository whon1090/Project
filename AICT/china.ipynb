{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## module import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "from pandas import DataFrame\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  if __name__ == '__main__':\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:58: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 17262 entries, 0 to 17261\n",
      "Data columns (total 20 columns):\n",
      "site         17262 non-null object\n",
      "code         17262 non-null object\n",
      "city         17262 non-null object\n",
      "date         17262 non-null int64\n",
      "hour         17262 non-null int64\n",
      "AQI          17262 non-null float64\n",
      "CO           17262 non-null float64\n",
      "CO_24h       17262 non-null float64\n",
      "NO2          17262 non-null float64\n",
      "NO2_24h      17262 non-null float64\n",
      "O3           17262 non-null float64\n",
      "O3_24h       17262 non-null float64\n",
      "O3_8h        17262 non-null float64\n",
      "O3_8h_24h    17262 non-null float64\n",
      "PM10         17262 non-null float64\n",
      "PM10_24h     17262 non-null float64\n",
      "PM2.5        17262 non-null float64\n",
      "PM2.5_24h    17262 non-null float64\n",
      "SO2          17262 non-null float64\n",
      "SO2_24h      17262 non-null float64\n",
      "dtypes: float64(15), int64(2), object(3)\n",
      "memory usage: 2.8+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:109: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##china load data\n",
    "\n",
    "##2017_1~4\n",
    "os.chdir('D:/data/china/2017/1')\n",
    "\n",
    "china_result = pd.DataFrame()\n",
    "for file in glob.glob(\"*.csv\"):\n",
    "    data = pd.read_csv(file, encoding='CP949')\n",
    "    china_result = pd.concat([china_result, data])\n",
    "\n",
    "\n",
    "del data\n",
    "\n",
    "china_2017 = pd.melt(china_result, id_vars=['date', 'hour','type'], var_name='code')\n",
    "\n",
    "\n",
    "del china_result\n",
    "\n",
    "china_test = china_2017\n",
    "\n",
    "\n",
    "china_test= china_test.groupby(['date', 'hour', 'code','type'])['value'].sum().unstack('type')\n",
    "\n",
    "china_test2= china_test.reset_index()\n",
    "\n",
    "\n",
    "del china_2017 ; del china_test\n",
    "\n",
    "os.chdir('D:/data/china')\n",
    "set_china = pd.read_csv('set.csv', encoding='UTF-8')\n",
    "\n",
    "# 사용할 변수인 북경, 탕산, 린이 지역 선정 - 22개의 set\n",
    "\n",
    "set_china = set_china.iloc[:, [0,1,2]]\n",
    "set_china.columns = ['code','city','site']\n",
    "set_test= set_china.set_index('site')\n",
    "set_test = set_test.loc[['唐山'],:]\n",
    "set_test= set_test.reset_index()\n",
    "\n",
    "# join set & china 샘플 모형 62920 * 20\n",
    "\n",
    "china_pm = pd.merge(set_test,china_test2, on='code', how= 'left')\n",
    "china_pm['site'].unique()\n",
    "\n",
    "\n",
    "china_pm['site'] = china_pm['site'].replace('唐山','탕산')\n",
    "china_pm.head(50)\n",
    "china_pm.to_csv(\"pm_ts.csv\", encoding=\"UTF-8\",index=False)\n",
    "# china_pm.columns = ['site','date','so2','co','o3','no2','pm10','pm2.5']\n",
    "\n",
    "### 2017 5~8\n",
    "os.chdir('D:/data/china/2017/2')\n",
    "os.getcwd()\n",
    "\n",
    "china_result = pd.DataFrame()\n",
    "for file in glob.glob(\"*.csv\"):\n",
    "    data = pd.read_csv(file, encoding='CP949')\n",
    "    china_result = pd.concat([china_result, data])\n",
    "\n",
    "\n",
    "del data\n",
    "\n",
    "china_2017 = pd.melt(china_result, id_vars=['date', 'hour','type'], var_name='code')\n",
    "\n",
    "\n",
    "del china_result\n",
    "\n",
    "china_test = china_2017\n",
    "\n",
    "\n",
    "china_test= china_test.groupby(['date', 'hour', 'code','type'])['value'].sum().unstack('type')\n",
    "china_test.head()\n",
    "\n",
    "china_test2= china_test.reset_index()\n",
    "\n",
    "\n",
    "del china_2017 ; del china_test\n",
    "\n",
    "os.chdir('D:/data/china')\n",
    "set_china = pd.read_csv('set.csv', encoding='UTF-8')\n",
    "\n",
    "# 사용할 변수인 북경, 탕산, 린이 지역 선정 - 22개의 set\n",
    "\n",
    "set_china = set_china.iloc[:, [0,1,2]]\n",
    "set_china.columns = ['code','city','site']\n",
    "set_test= set_china.set_index('site')\n",
    "set_test = set_test.loc[['唐山'],:]\n",
    "set_test= set_test.reset_index()\n",
    "\n",
    "# join set & china 샘플 모형 62920 * 20\n",
    "\n",
    "china_pm = pd.merge(set_test,china_test2, on='code', how= 'left')\n",
    "china_pm.info()\n",
    "china_pm['site'].unique()\n",
    "china_pm.head()\n",
    "\n",
    "\n",
    "china_pm['site'] = china_pm['site'].replace('唐山','탕산')\n",
    "china_pm.head(50)\n",
    "china_pm.to_csv(\"pm_ts2.csv\", encoding=\"UTF-8\",index=False)\n",
    "\n",
    "# 9~ 12\n",
    "os.chdir('D:/data/china/2017/3')\n",
    "os.getcwd()\n",
    "\n",
    "china_result = pd.DataFrame()\n",
    "for file in glob.glob(\"*.csv\"):\n",
    "    data = pd.read_csv(file, encoding='CP949')\n",
    "    china_result = pd.concat([china_result, data])\n",
    "\n",
    "del data\n",
    "\n",
    "china_2017 = pd.melt(china_result, id_vars=['date', 'hour','type'], var_name='code')\n",
    "\n",
    "del china_result\n",
    "\n",
    "china_test = china_2017\n",
    "\n",
    "\n",
    "china_test= china_test.groupby(['date', 'hour', 'code','type'])['value'].sum().unstack('type')\n",
    "\n",
    "china_test2= china_test.reset_index()\n",
    "\n",
    "del china_2017 ; del china_test\n",
    "\n",
    "os.chdir('D:/data/china')\n",
    "set_china = pd.read_csv('set.csv', encoding='UTF-8')\n",
    "\n",
    "# 사용할 변수인 북경, 탕산, 린이 지역 선정 - 22개의 set\n",
    "\n",
    "set_china = set_china.iloc[:, [0,1,2]]\n",
    "set_china.columns = ['code','city','site']\n",
    "set_test= set_china.set_index('site')\n",
    "set_test = set_test.loc[['唐山'],:]\n",
    "set_test= set_test.reset_index()\n",
    "\n",
    "# join set & china 샘플 모형 62920 * 20\n",
    "\n",
    "china_pm = pd.merge(set_test,china_test2, on='code', how= 'left')\n",
    "\n",
    "\n",
    "china_pm['site'] = china_pm['site'].replace('唐山','탕산')\n",
    "china_pm.to_csv(\"pm_ts3.csv\", encoding=\"UTF-8\",index=False)\n",
    "\n",
    "\n",
    "china_pm_1 = pd.read_csv('pm_ts.csv', encoding= 'UTF-8')\n",
    "china_pm_2 = pd.read_csv('pm_ts2.csv', encoding= 'UTF-8')\n",
    "china_pm_3 = pd.read_csv('pm_ts3.csv', encoding= 'UTF-8')\n",
    "\n",
    "china_2017 = pd.concat([china_pm_1,china_pm_2,china_pm_3])\n",
    "china_2017.to_csv(\"pm_2017_ts.csv\", encoding=\"UTF-8\",index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  import sys\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:46: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:86: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##2018_1~4\n",
    "os.chdir('D:/data/china/2018/1')\n",
    "\n",
    "china_result = pd.DataFrame()\n",
    "for file in glob.glob(\"*.csv\"):\n",
    "    data = pd.read_csv(file, encoding='CP949')\n",
    "    china_result = pd.concat([china_result, data])\n",
    "\n",
    "del data\n",
    "\n",
    "china_2018 = pd.melt(china_result, id_vars=['date', 'hour','type'], var_name='code')\n",
    "\n",
    "del china_result\n",
    "\n",
    "\n",
    "china_2018= china_2018.groupby(['date', 'hour', 'code','type'])['value'].sum().unstack('type')\n",
    "\n",
    "china_test2= china_2018.reset_index()\n",
    "del china_2018\n",
    "\n",
    "os.chdir('D:/data/china')\n",
    "set_china = pd.read_csv('set.csv', encoding='UTF-8')\n",
    "\n",
    "# 사용할 변수인 북경, 탕산, 린이 지역 선정 - 22개의 set\n",
    "\n",
    "set_china = set_china.iloc[:, [0,1,2]]\n",
    "set_china.columns = ['code','city','site']\n",
    "set_test= set_china.set_index('site')\n",
    "set_test = set_test.loc[['唐山'],:]\n",
    "set_test= set_test.reset_index()\n",
    "\n",
    "# join set & china 샘플 모형 62920 * 20\n",
    "\n",
    "china_pm = pd.merge(set_test,china_test2, on='code', how= 'left')\n",
    "\n",
    "china_pm['site'] = china_pm['site'].replace('唐山','탕산')\n",
    "china_pm.to_csv(\"pm_ts.csv\", encoding=\"UTF-8\",index=False)\n",
    "# china_pm.columns = ['site','date','so2','co','o3','no2','pm10','pm2.5']\n",
    "\n",
    "### 2018 5~8\n",
    "os.chdir('D:/data/china/2018/2')\n",
    "\n",
    "china_result = pd.DataFrame()\n",
    "for file in glob.glob(\"*.csv\"):\n",
    "    data = pd.read_csv(file, encoding='CP949')\n",
    "    china_result = pd.concat([china_result, data])\n",
    "\n",
    "del data\n",
    "\n",
    "china_2018 = pd.melt(china_result, id_vars=['date', 'hour','type'], var_name='code')\n",
    "\n",
    "del china_result\n",
    "\n",
    "china_2018= china_2018.groupby(['date', 'hour', 'code','type'])['value'].sum().unstack('type')\n",
    "\n",
    "\n",
    "china_test2= china_2018.reset_index()\n",
    "\n",
    "del china_2018;\n",
    "\n",
    "os.chdir('D:/data/china')\n",
    "set_china = pd.read_csv('set.csv', encoding='UTF-8')\n",
    "\n",
    "# 사용할 변수인 북경, 탕산, 린이 지역 선정 - 22개의 set\n",
    "\n",
    "set_china = set_china.iloc[:, [0,1,2]]\n",
    "set_china.columns = ['code','city','site']\n",
    "set_test= set_china.set_index('site')\n",
    "set_test = set_test.loc[['唐山'],:]\n",
    "set_test= set_test.reset_index()\n",
    "\n",
    "# join set & china 샘플 모형 62920 * 20\n",
    "\n",
    "china_pm = pd.merge(set_test,china_test2, on='code', how= 'left')\n",
    "\n",
    "china_pm['site'] = china_pm['site'].replace('唐山','탕산')\n",
    "china_pm.to_csv(\"pm_ts2.csv\", encoding=\"UTF-8\",index=False)\n",
    "\n",
    "# date 9~ 12\n",
    "os.chdir('D:/data/china/2018/3')\n",
    "os.getcwd()\n",
    "\n",
    "china_result = pd.DataFrame()\n",
    "for file in glob.glob(\"*.csv\"):\n",
    "    data = pd.read_csv(file, encoding='CP949')\n",
    "    china_result = pd.concat([china_result, data])\n",
    "\n",
    "\n",
    "# china2018년 9월 ~12월만 특정행들이 추가되고 변형되어있어 다시 formatting\n",
    "del data\n",
    "china_result= china_result.drop('<html>',axis=1)\n",
    "\n",
    "\n",
    "china_2018 = pd.melt(china_result, id_vars=['date', 'hour','type'], var_name='code')\n",
    "\n",
    "del china_result\n",
    "\n",
    "# 다른 2017~2018년도에는 date, hour, type의 null값이 존재하지 않았으나\n",
    "# 해당연도에는 약 48000개의 null값이 발생하여 제거하고 진행\n",
    "china_2018=china_2018.dropna(subset=['date','hour','type'])\n",
    "\n",
    "\n",
    "china_2018= china_2018.groupby(['date', 'hour', 'code','type'])['value'].sum().unstack('type')\n",
    "china_test2= china_2018.reset_index()\n",
    "\n",
    "\n",
    "del china_2018\n",
    "\n",
    "os.chdir('D:/data/china')\n",
    "set_china = pd.read_csv('set.csv', encoding='UTF-8')\n",
    "\n",
    "# 사용할 변수인 북경, 탕산, 린이 지역 선정 - 22개의 set\n",
    "\n",
    "set_china = set_china.iloc[:, [0,1,2]]\n",
    "set_china.columns = ['code','city','site']\n",
    "set_test= set_china.set_index('site')\n",
    "set_test = set_test.loc[['唐山'],:]\n",
    "set_test= set_test.reset_index()\n",
    "\n",
    "# join set & china 샘플 모형 62920 * 20\n",
    "\n",
    "china_pm = pd.merge(set_test,china_test2, on='code', how= 'left')\n",
    "\n",
    "china_pm['site'] = china_pm['site'].replace('唐山','탕산')\n",
    "china_pm.to_csv(\"pm_ts3.csv\", encoding=\"UTF-8\",index=False)\n",
    "\n",
    "\n",
    "china_pm_1 = pd.read_csv('pm_ts.csv', encoding= 'UTF-8')\n",
    "china_pm_2 = pd.read_csv('pm_ts2.csv', encoding= 'UTF-8')\n",
    "china_pm_3 = pd.read_csv('pm_ts3.csv', encoding= 'UTF-8')\n",
    "\n",
    "china_2018 = pd.concat([china_pm_1,china_pm_2,china_pm_3])\n",
    "china_2018.to_csv(\"pm_2018_ts.csv\", encoding=\"UTF-8\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2019 1~4\n",
    "os.chdir('D:/data/china/2019/1')\n",
    "\n",
    "china_result = pd.DataFrame()\n",
    "for file in glob.glob(\"*.csv\"):\n",
    "    data = pd.read_csv(file, encoding='CP949')\n",
    "    china_result = pd.concat([china_result, data])\n",
    "\n",
    "del data\n",
    "\n",
    "china_result.isnull().sum()\n",
    "\n",
    "china_2019 = pd.melt(china_result, id_vars=['date', 'hour','type'], var_name='code')\n",
    "\n",
    "del china_result\n",
    "\n",
    "china_2019= china_2019.groupby(['date', 'hour', 'code','type'])['value'].sum().unstack('type')\n",
    "\n",
    "\n",
    "china_test2= china_2019.reset_index()\n",
    "\n",
    "del china_2019;\n",
    "\n",
    "os.chdir('D:/data/china')\n",
    "set_china = pd.read_csv('set.csv', encoding='UTF-8')\n",
    "\n",
    "# 사용할 변수인 북경, 탕산, 린이 지역 선정 - 22개의 set\n",
    "\n",
    "set_china = set_china.iloc[:, [0,1,2]]\n",
    "set_china.columns = ['code','city','site']\n",
    "set_test= set_china.set_index('site')\n",
    "set_test = set_test.loc[['唐山'],:]\n",
    "set_test= set_test.reset_index()\n",
    "\n",
    "# join set & china 샘플 모형 62920 * 20\n",
    "\n",
    "china_pm = pd.merge(set_test,china_test2, on='code', how= 'left')\n",
    "\n",
    "china_pm['site'] = china_pm['site'].replace('唐山','탕산')\n",
    "china_pm.to_csv(\"pm_ts.csv\", encoding=\"UTF-8\",index=False)\n",
    "\n",
    "# 2019 date 5~6\n",
    "os.chdir('D:/data/china/2019/2')\n",
    "\n",
    "china_result = pd.DataFrame()\n",
    "for file in glob.glob(\"*.csv\"):\n",
    "    data = pd.read_csv(file, encoding='CP949')\n",
    "    china_result = pd.concat([china_result, data])\n",
    "\n",
    "del data\n",
    "\n",
    "\n",
    "china_2019 = pd.melt(china_result, id_vars=['date', 'hour','type'], var_name='code')\n",
    "\n",
    "del china_result\n",
    "\n",
    "\n",
    "china_2019= china_2019.groupby(['date', 'hour', 'code','type'])['value'].sum().unstack('type')\n",
    "china_test2= china_2019.reset_index()\n",
    "\n",
    "\n",
    "del china_2019\n",
    "\n",
    "os.chdir('D:/data/china')\n",
    "set_china = pd.read_csv('set.csv', encoding='UTF-8')\n",
    "\n",
    "# 사용할 변수인 북경, 탕산, 린이 지역 선정 - 22개의 set\n",
    "\n",
    "set_china = set_china.iloc[:, [0,1,2]]\n",
    "set_china.columns = ['code','city','site']\n",
    "set_test= set_china.set_index('site')\n",
    "set_test = set_test.loc[['唐山'],:]\n",
    "set_test= set_test.reset_index()\n",
    "\n",
    "# join set & china 샘플 모형 62920 * 20\n",
    "\n",
    "china_pm = pd.merge(set_test,china_test2, on='code', how= 'left')\n",
    "\n",
    "china_pm['site'] = china_pm['site'].replace('唐山','탕산')\n",
    "china_pm.to_csv(\"pm_ts2.csv\", encoding=\"UTF-8\",index=False)\n",
    "\n",
    "\n",
    "china_pm_1 = pd.read_csv('pm_ts.csv', encoding= 'UTF-8')\n",
    "china_pm_2 = pd.read_csv('pm_ts2.csv', encoding= 'UTF-8')\n",
    "\n",
    "china_2019 = pd.concat([china_pm_1,china_pm_2])\n",
    "china_2019.to_csv(\"pm_2019_ts.csv\", encoding=\"UTF-8\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data merge \n",
    "\n",
    "china_2017= pd.read_csv('pm_2017_ts.csv', encoding=\"UTF-8\")\n",
    "china_2018= pd.read_csv('pm_2018_ts.csv', encoding=\"UTF-8\")\n",
    "china_2019= pd.read_csv('pm_2019_ts.csv', encoding=\"UTF-8\")\n",
    "\n",
    "china_pm = pd.concat([china_2017,china_2018,china_2019])\n",
    "\n",
    "# 저장시 나오는 column 제거\n",
    "# china_pm= china_pm.drop(['Unnamed: 0','Unnamed: 0.1'],axis=1)\n",
    "china_pm.drop(['code','city','AQI'],axis=1,inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "china_pm[['date','hour']] = china_pm[['date','hour']].astype(str)\n",
    "china_pm['date'] = china_pm['date'].str[0:-2]\n",
    "china_pm['hour'] = china_pm['hour'].str[0:-2] + \":00\" \n",
    "text = ['0:00', '1:00', '2:00', '3:00', '4:00', '5:00', '6:00', '7:00', '8:00', '9:00']\n",
    "change_text = ['00:00', '01:00', '02:00', '03:00', '04:00', '05:00', '06:00', '07:00', '08:00', '09:00']\n",
    "\n",
    "for i, j in zip(text, change_text):\n",
    "    china_pm['hour'] = china_pm['hour'].replace(i, j)\n",
    "    \n",
    "china_pm['date'] = china_pm['date']+ \" \" +china_pm['hour']\n",
    "china_pm['date'] = pd.to_datetime(china_pm['date'], format='%Y-%m-%d %H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby data\n",
    "china_pm.dropna(inplace=True)\n",
    "china_pm.drop(['hour'],axis=1,inplace=True)\n",
    "china_pm = china_pm.pivot_table(index=[\"date\",\"site\"], margins=True, aggfunc='mean').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>site</th>\n",
       "      <th>CO</th>\n",
       "      <th>CO_24h</th>\n",
       "      <th>NO2</th>\n",
       "      <th>NO2_24h</th>\n",
       "      <th>O3</th>\n",
       "      <th>O3_24h</th>\n",
       "      <th>O3_8h</th>\n",
       "      <th>O3_8h_24h</th>\n",
       "      <th>PM10</th>\n",
       "      <th>PM10_24h</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM2.5_24h</th>\n",
       "      <th>SO2</th>\n",
       "      <th>SO2_24h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "      <td>탕산</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>72</td>\n",
       "      <td>75</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>260</td>\n",
       "      <td>0</td>\n",
       "      <td>212</td>\n",
       "      <td>25</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-01 01:00:00</td>\n",
       "      <td>탕산</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>73</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>197</td>\n",
       "      <td>260</td>\n",
       "      <td>150</td>\n",
       "      <td>211</td>\n",
       "      <td>29</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-01 02:00:00</td>\n",
       "      <td>탕산</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>74</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>170</td>\n",
       "      <td>258</td>\n",
       "      <td>126</td>\n",
       "      <td>210</td>\n",
       "      <td>24</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-01 03:00:00</td>\n",
       "      <td>탕산</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>132</td>\n",
       "      <td>254</td>\n",
       "      <td>103</td>\n",
       "      <td>207</td>\n",
       "      <td>19</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-01 04:00:00</td>\n",
       "      <td>탕산</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>86</td>\n",
       "      <td>93</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>145</td>\n",
       "      <td>322</td>\n",
       "      <td>127</td>\n",
       "      <td>260</td>\n",
       "      <td>19</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date site  CO  CO_24h  NO2  NO2_24h  O3  O3_24h  O3_8h  \\\n",
       "0  2017-01-01 00:00:00   탕산   3       3   72       75   3      15      4   \n",
       "1  2017-01-01 01:00:00   탕산   3       3   73       75   2      15      2   \n",
       "2  2017-01-01 02:00:00   탕산   3       3   74       75   2      15      2   \n",
       "3  2017-01-01 03:00:00   탕산   3       3   70       75   2      15      2   \n",
       "4  2017-01-01 04:00:00   탕산   3       3   86       93   4      20      4   \n",
       "\n",
       "   O3_8h_24h  PM10  PM10_24h  PM2.5  PM2.5_24h  SO2  SO2_24h  \n",
       "0         10     0       260      0        212   25       35  \n",
       "1          2   197       260    150        211   29       35  \n",
       "2          2   170       258    126        210   24       34  \n",
       "3          2   132       254    103        207   19       33  \n",
       "4          4   145       322    127        260   19       40  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "china_column =china_pm.columns.tolist()\n",
    "china_column.remove('date')\n",
    "china_column.remove('site')\n",
    "for i in china_column :\n",
    "    china_pm[i] = china_pm[i].apply(lambda x: round(x))\n",
    "\n",
    "china_pm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "china_pm.to_csv('D:/data/china_site_final.csv',encoding='CP949',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "china_pm.drop(['site'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "china_pm.to_csv('D:/data/chinapm_final.csv',encoding='CP949',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test set 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# 2019 date 7~11\n",
    "os.chdir('D:/data/china/2019/3')\n",
    "os.getcwd()\n",
    "\n",
    "china_result = pd.DataFrame()\n",
    "for file in glob.glob(\"*.csv\"):\n",
    "    data = pd.read_csv(file, encoding='CP949')\n",
    "    china_result = pd.concat([china_result, data])\n",
    "\n",
    "del data\n",
    "\n",
    "\n",
    "china_2019 = pd.melt(china_result, id_vars=['date', 'hour','type'], var_name='code')\n",
    "\n",
    "del china_result\n",
    "\n",
    "\n",
    "china_2019= china_2019.groupby(['date', 'hour', 'code','type'])['value'].sum().unstack('type')\n",
    "china_test2= china_2019.reset_index()\n",
    "\n",
    "\n",
    "del china_2019\n",
    "\n",
    "os.chdir('D:/data/china')\n",
    "set_china = pd.read_csv('set.csv', encoding='UTF-8')\n",
    "\n",
    "# 사용할 변수인 북경, 탕산, 린이 지역 선정 - 22개의 set\n",
    "\n",
    "set_china = set_china.iloc[:, [0,1,2]]\n",
    "set_china.columns = ['code','city','site']\n",
    "set_test= set_china.set_index('site')\n",
    "set_test = set_test.loc[['唐山'],:]\n",
    "set_test= set_test.reset_index()\n",
    "\n",
    "# join set & china 샘플 모형 62920 * 20\n",
    "\n",
    "china_pm = pd.merge(set_test,china_test2, on='code', how= 'left')\n",
    "\n",
    "china_pm['site'] = china_pm['site'].replace('唐山','탕산')\n",
    "\n",
    "\n",
    "# 2019 date other\n",
    "os.chdir('D:/data/china/2019/5')\n",
    "\n",
    "china_result = pd.DataFrame()\n",
    "for file in glob.glob(\"*.csv\"):\n",
    "    data = pd.read_csv(file, encoding='UTF-8')\n",
    "    china_result = pd.concat([china_result, data])\n",
    "\n",
    "del data\n",
    "\n",
    "china_2019 = pd.melt(china_result, id_vars=['date', 'hour','type'], var_name='code')\n",
    "\n",
    "del china_result\n",
    "\n",
    "china_2019= china_2019.groupby(['date', 'hour', 'code','type'])['value'].sum().unstack('type')\n",
    "china_test2= china_2019.reset_index()\n",
    "\n",
    "del china_2019\n",
    "\n",
    "os.chdir('D:/data/china')\n",
    "set_china = pd.read_csv('set.csv', encoding='UTF-8')\n",
    "\n",
    "# 사용할 변수인 북경, 탕산, 린이 지역 선정 - 22개의 set\n",
    "\n",
    "set_china = set_china.iloc[:, [0,1,2]]\n",
    "set_china.columns = ['code','city','site']\n",
    "set_test= set_china.set_index('site')\n",
    "set_test = set_test.loc[['唐山'],:]\n",
    "set_test= set_test.reset_index()\n",
    "\n",
    "# join set & china 샘플 모형 62920 * 20\n",
    "\n",
    "china_pm2 = pd.merge(set_test,china_test2, on='code', how= 'left')\n",
    "china_pm2['site'] = china_pm2['site'].replace('唐山','탕산')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "china_pm = pd.concat([china_pm,china_pm2])\n",
    "china_pm.drop(['code','city','AQI'],axis=1,inplace= True)\n",
    "china_pm[['date','hour']] = china_pm[['date','hour']].astype(str)\n",
    "china_pm['hour'] = china_pm['hour'] + \":00\" \n",
    "text = ['0:00', '1:00', '2:00', '3:00', '4:00', '5:00', '6:00', '7:00', '8:00', '9:00']\n",
    "change_text = ['00:00', '01:00', '02:00', '03:00', '04:00', '05:00', '06:00', '07:00', '08:00', '09:00']\n",
    "\n",
    "for i, j in zip(text, change_text):\n",
    "    china_pm['hour'] = china_pm['hour'].replace(i, j)\n",
    "\n",
    "china_pm['date'] = china_pm['date']+ \" \" +china_pm['hour']\n",
    "china_pm['date'] = pd.to_datetime(china_pm['date'], format='%Y-%m-%d %H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "china_pm.dropna(inplace=True)\n",
    "china_pm.drop(['hour'],axis=1,inplace=True)\n",
    "china_pm = china_pm.pivot_table(index=[\"date\",\"site\"], margins=True, aggfunc='mean').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>PM10</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM2.5_24h</th>\n",
       "      <th>PM10_24h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-07-01 00:00:00</td>\n",
       "      <td>61</td>\n",
       "      <td>26</td>\n",
       "      <td>25</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-07-01 01:00:00</td>\n",
       "      <td>70</td>\n",
       "      <td>26</td>\n",
       "      <td>25</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-07-01 02:00:00</td>\n",
       "      <td>79</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-07-01 03:00:00</td>\n",
       "      <td>79</td>\n",
       "      <td>30</td>\n",
       "      <td>26</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-07-01 04:00:00</td>\n",
       "      <td>76</td>\n",
       "      <td>34</td>\n",
       "      <td>26</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date  PM10  PM2.5  PM2.5_24h  PM10_24h\n",
       "0  2019-07-01 00:00:00    61     26         25        54\n",
       "1  2019-07-01 01:00:00    70     26         25        55\n",
       "2  2019-07-01 02:00:00    79     27         26        56\n",
       "3  2019-07-01 03:00:00    79     30         26        58\n",
       "4  2019-07-01 04:00:00    76     34         26        59"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "china_column =china_pm.columns.tolist()\n",
    "china_column.remove('date')\n",
    "china_column.remove('site')\n",
    "for i in china_column :\n",
    "    china_pm[i] = china_pm[i].apply(lambda x: round(x))\n",
    "\n",
    "china_test_all = china_pm.copy()\n",
    "    \n",
    "china_pm = china_pm[['date','PM10','PM2.5','PM2.5_24h','PM10_24h']]\n",
    "china_pm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "china_pm.to_csv('D:/data/china_test_final.csv',encoding='CP949',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# site 포함 아닌거 둘다 Full - set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>site</th>\n",
       "      <th>CO</th>\n",
       "      <th>CO_24h</th>\n",
       "      <th>NO2</th>\n",
       "      <th>NO2_24h</th>\n",
       "      <th>O3</th>\n",
       "      <th>O3_24h</th>\n",
       "      <th>O3_8h</th>\n",
       "      <th>O3_8h_24h</th>\n",
       "      <th>PM10</th>\n",
       "      <th>PM10_24h</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM2.5_24h</th>\n",
       "      <th>SO2</th>\n",
       "      <th>SO2_24h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-07-01 00:00:00</td>\n",
       "      <td>탕산</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>26</td>\n",
       "      <td>38</td>\n",
       "      <td>152</td>\n",
       "      <td>84</td>\n",
       "      <td>137</td>\n",
       "      <td>61</td>\n",
       "      <td>54</td>\n",
       "      <td>26</td>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-07-01 01:00:00</td>\n",
       "      <td>탕산</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>28</td>\n",
       "      <td>31</td>\n",
       "      <td>152</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>70</td>\n",
       "      <td>55</td>\n",
       "      <td>26</td>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-07-01 02:00:00</td>\n",
       "      <td>탕산</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>29</td>\n",
       "      <td>12</td>\n",
       "      <td>152</td>\n",
       "      <td>21</td>\n",
       "      <td>31</td>\n",
       "      <td>79</td>\n",
       "      <td>56</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-07-01 03:00:00</td>\n",
       "      <td>탕산</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>31</td>\n",
       "      <td>15</td>\n",
       "      <td>152</td>\n",
       "      <td>19</td>\n",
       "      <td>31</td>\n",
       "      <td>79</td>\n",
       "      <td>58</td>\n",
       "      <td>30</td>\n",
       "      <td>26</td>\n",
       "      <td>18</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-07-01 04:00:00</td>\n",
       "      <td>탕산</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>32</td>\n",
       "      <td>20</td>\n",
       "      <td>152</td>\n",
       "      <td>20</td>\n",
       "      <td>32</td>\n",
       "      <td>76</td>\n",
       "      <td>59</td>\n",
       "      <td>34</td>\n",
       "      <td>26</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date site  CO  CO_24h  NO2  NO2_24h  O3  O3_24h  O3_8h  \\\n",
       "0  2019-07-01 00:00:00   탕산   1       1   47       26  38     152     84   \n",
       "1  2019-07-01 01:00:00   탕산   1       1   51       28  31     152     31   \n",
       "2  2019-07-01 02:00:00   탕산   1       1   69       29  12     152     21   \n",
       "3  2019-07-01 03:00:00   탕산   2       1   66       31  15     152     19   \n",
       "4  2019-07-01 04:00:00   탕산   2       1   55       32  20     152     20   \n",
       "\n",
       "   O3_8h_24h  PM10  PM10_24h  PM2.5  PM2.5_24h  SO2  SO2_24h  \n",
       "0        137    61        54     26         25   17       22  \n",
       "1         31    70        55     26         25   17       21  \n",
       "2         31    79        56     27         26   17       21  \n",
       "3         31    79        58     30         26   18       21  \n",
       "4         32    76        59     34         26   20       21  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "china_test_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Site 포함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "china_before = pd.read_csv('D:/data/china_site_final.csv',encoding='CP949')\n",
    "china_before = china_before[['date','site','PM10','PM2.5','PM2.5_24h','PM10_24h','CO','O3','NO2','SO2']]\n",
    "china_test_all = china_test_all[['date','site','PM10','PM2.5','PM2.5_24h','PM10_24h','CO','O3','NO2','SO2']]\n",
    "china_merge = pd.concat([china_before,china_test_all])\n",
    "china_merge = china_merge[china_merge['date']!='All']\n",
    "china_merge.to_csv('D:/data/china_site_2020.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "china_merge.to_csv('D:/data/china_site_2020.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Site 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "china_merge.drop('site',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "china_merge.to_csv('D:/data/china_merge_2020.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
